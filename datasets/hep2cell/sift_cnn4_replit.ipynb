{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# replit claude sonnet related code, sift cnn descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting load_data...\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 161\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTotal execution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_duration\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 112\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m total_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Extract SIFT descriptors\u001b[39;00m\n\u001b[1;32m    115\u001b[0m descriptors \u001b[38;5;241m=\u001b[39m extract_sift_descriptors(images)\n",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m, in \u001b[0;36mtiming_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     18\u001b[0m duration \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[1], line 43\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mbytearray\u001b[39m(response\u001b[38;5;241m.\u001b[39mcontent), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m     42\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimdecode(img_array, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m---> 43\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m     45\u001b[0m images\u001b[38;5;241m.\u001b[39mappend(img)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def timing_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        print(f\"\\nStarting {func.__name__}...\")\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"Completed {func.__name__} in {duration:.2f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timing_decorator\n",
    "def load_data():\n",
    "    # Load image paths\n",
    "    response = requests.get('https://raw.githubusercontent.com/RyanS974/RyanS974/main/datasets/hep2cell/cells2.txt')\n",
    "    image_paths = response.text.strip().split('\\n')[:5000]\n",
    "\n",
    "    # Load labels\n",
    "    response = requests.get('https://raw.githubusercontent.com/RyanS974/RyanS974/main/datasets/hep2cell/labels.mat')\n",
    "    with open('labels.mat', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    labels = loadmat('labels.mat')['labels'][:5000]\n",
    "\n",
    "    # Load and preprocess images\n",
    "    images = []\n",
    "    base_url = 'https://raw.githubusercontent.com/RyanS974/RyanS974/main/datasets/hep2cell/cells/'\n",
    "\n",
    "    for path in image_paths:\n",
    "        response = requests.get(base_url + path)\n",
    "        img_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (96, 96))\n",
    "        img = img / 255.0\n",
    "        images.append(img)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "@timing_decorator\n",
    "def extract_sift_descriptors(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    all_descriptors = []\n",
    "\n",
    "    for img in images:\n",
    "        img_uint8 = (img * 255).astype(np.uint8)\n",
    "        keypoints, descriptors = sift.detectAndCompute(img_uint8, None)\n",
    "        if descriptors is None:\n",
    "            descriptors = np.zeros((1, 128))\n",
    "        # Pad or truncate descriptors to fixed size\n",
    "        if descriptors.shape[0] > 32:\n",
    "            descriptors = descriptors[:32]\n",
    "        else:\n",
    "            pad_size = 32 - descriptors.shape[0]\n",
    "            descriptors = np.pad(descriptors, ((0, pad_size), (0, 0)))\n",
    "        all_descriptors.append(descriptors)\n",
    "\n",
    "    return np.array(all_descriptors)\n",
    "\n",
    "def create_model(input_shape, descriptor_shape):\n",
    "    # Image input branch\n",
    "    img_input = Input(shape=input_shape)\n",
    "    x1 = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "    x1 = MaxPooling2D()(x1)\n",
    "    x1 = Conv2D(64, (3, 3), activation='relu')(x1)\n",
    "    x1 = MaxPooling2D()(x1)\n",
    "    x1 = Flatten()(x1)\n",
    "\n",
    "    # SIFT descriptor branch\n",
    "    desc_input = Input(shape=descriptor_shape)\n",
    "    x2 = Flatten()(desc_input)\n",
    "    x2 = Dense(128, activation='relu')(x2)\n",
    "\n",
    "    # Concatenate both branches\n",
    "    concat = Concatenate()([x1, x2])\n",
    "    x = Dense(128, activation='relu')(concat)\n",
    "    output = Dense(6, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[img_input, desc_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "@timing_decorator\n",
    "def visualize_samples(images, images_with_sift):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "    for i in range(5):\n",
    "        axes[0, i].imshow(images[i], cmap='gray')\n",
    "        axes[0, i].set_title(f'Original {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        axes[1, i].imshow(images_with_sift[i], cmap='gray')\n",
    "        axes[1, i].set_title(f'With SIFT {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    total_start = time.time()\n",
    "\n",
    "    # Load and preprocess data\n",
    "    images, labels = load_data()\n",
    "\n",
    "    # Extract SIFT descriptors\n",
    "    descriptors = extract_sift_descriptors(images)\n",
    "\n",
    "    # Prepare images with SIFT visualization\n",
    "    sift = cv2.SIFT_create()\n",
    "    images_with_sift = []\n",
    "    for i in range(5):\n",
    "        img = (images[i] * 255).astype(np.uint8)\n",
    "        keypoints, _ = sift.detectAndCompute(img, None)\n",
    "        img_with_kp = cv2.drawKeypoints(img, keypoints, None)\n",
    "        images_with_sift.append(img_with_kp)\n",
    "\n",
    "    # Visualize samples\n",
    "    visualize_samples(images[:5], images_with_sift)\n",
    "\n",
    "    # Split dataset\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    desc_train, desc_temp = train_test_split(descriptors, test_size=0.3, random_state=42)\n",
    "    desc_val, desc_test = train_test_split(desc_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create and train model\n",
    "    model = create_model((96, 96, 1), (32, 128))\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    train_start = time.time()\n",
    "    history = model.fit(\n",
    "        [X_train.reshape(-1, 96, 96, 1), desc_train],\n",
    "        y_train,\n",
    "        validation_data=([X_val.reshape(-1, 96, 96, 1), desc_val], y_val),\n",
    "        epochs=10,\n",
    "        batch_size=32\n",
    "    )\n",
    "    print(f\"Training completed in {time.time() - train_start:.2f} seconds\")\n",
    "\n",
    "    # Evaluate model\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    test_start = time.time()\n",
    "    test_loss, test_acc = model.evaluate([X_test.reshape(-1, 96, 96, 1), desc_test], y_test)\n",
    "    print(f\"Testing completed in {time.time() - test_start:.2f} seconds\")\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    total_duration = time.time() - total_start\n",
    "    print(f\"\\nTotal execution time: {total_duration:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
