{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d6d55b",
   "metadata": {},
   "source": [
    "# CSC 546 Project on the HEp-2 Cells dataset.  Ryan Smith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd7e3a5",
   "metadata": {},
   "source": [
    "# Basic information on the matlab file, labels.mat using SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc9a79c-fc6a-4594-95cf-58efe4977b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 63445)\n",
      "63445\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "# Load the .mat file\n",
    "mat_file = sio.loadmat('labels.mat')\n",
    "\n",
    "# Access the variables\n",
    "labels = mat_file['labels']\n",
    "\n",
    "# Print the shape of the array\n",
    "print(labels.shape) \n",
    "\n",
    "# Print the total number of data points\n",
    "print(labels.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b06f6d",
   "metadata": {},
   "source": [
    "# Full Code From Start to Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c0bf3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: Loading labels\n",
      "Number of labels: 63445\n",
      "Phase 1 completed in 0.00 seconds\n",
      "Phase 2: Loading image paths\n",
      "Number of image paths: 63445\n",
      "Phase 2 completed in 0.01 seconds\n",
      "Phase 3: Randomly selecting 1% of data\n",
      "Sample size: 634\n",
      "Sample indices size: 634\n",
      "Sample paths size: 634\n",
      "Sample labels size: 634\n",
      "Phase 3 completed in 0.00 seconds\n",
      "Phase 4: Preprocessing images\n",
      "Unique label values before saving: [0 1 2 3 4 5]\n",
      "Saved preprocessed images, labels, and SIFT features to disk.\n",
      "Valid images size: 300\n",
      "Valid labels size: 300\n",
      "Unique label values after loading from disk: [0 1 2 3 4 5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 4 completed in 1444.58 seconds\n",
      "Phase 5: Splitting data into training and validation sets\n",
      "Phase 5 completed in 0.01 seconds\n",
      "Unique training labels: [0 1 2 3 4 5]\n",
      "Unique validation labels: [0 1 2 3 4 5]\n",
      "Phase 6: Building CNN model\n",
      "Phase 6 completed in 0.03 seconds\n",
      "Phase 7: Training CNN model\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.2738 - loss: 1.7199 - val_accuracy: 0.3333 - val_loss: 1.5770\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.3357 - loss: 1.4982 - val_accuracy: 0.4500 - val_loss: 1.4130\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.4685 - loss: 1.2553 - val_accuracy: 0.4667 - val_loss: 1.2685\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5205 - loss: 1.0929 - val_accuracy: 0.4833 - val_loss: 1.2056\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.5665 - loss: 1.0050 - val_accuracy: 0.5333 - val_loss: 1.1152\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.6045 - loss: 0.8675 - val_accuracy: 0.5667 - val_loss: 1.1971\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7120 - loss: 0.8162 - val_accuracy: 0.4833 - val_loss: 1.3625\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5843 - loss: 0.9897 - val_accuracy: 0.6000 - val_loss: 1.1012\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.6788 - loss: 0.7121 - val_accuracy: 0.5167 - val_loss: 1.3283\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7076 - loss: 0.6783 - val_accuracy: 0.6833 - val_loss: 1.0460\n",
      "Phase 7 completed in 7.23 seconds\n",
      "Phase 8: Evaluating model\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6639 - loss: 0.9800\n",
      "Validation Accuracy: 0.6833333373069763\n",
      "Phase 8 completed in 0.07 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Description:\n",
    "# This script performs supervised learning for classifying biological cell images. It starts by loading labels from a MATLAB file and image paths from a text file. It then randomly selects 1% of the data for processing if preprocessed data is not already saved. The images are preprocessed by resizing to 128x128 pixels, scaling, and adding a channel dimension. The data is split into training and validation sets. A Convolutional Neural Network (CNN) is built and trained on the training set, and its performance is evaluated on the validation set. The script includes error handling for missing images and prints messages indicating the current phase of processing, along with timers to measure the time taken for each phase. Intermediate results are saved to disk to speed up future runs.\n",
    "\n",
    "# Check if preprocessed images and labels are already saved\n",
    "# This section checks if the preprocessed images and labels are already saved on disk. If the files 'preprocessed_images.npy' and 'valid_labels.npy' exist, it loads the preprocessed images and labels from these files. This avoids redundant preprocessing and ensures consistency in the data used for training and validation. If the files do not exist, the script proceeds to load and preprocess the data.\n",
    "if os.path.exists('preprocessed_images.npy') and os.path.exists('valid_labels.npy') and os.path.exists('sift_features.npy'):\n",
    "    print(\"Loading preprocessed images, labels, and SIFT features from disk.\")\n",
    "    images = np.load('preprocessed_images.npy')\n",
    "    valid_labels = np.load('valid_labels.npy')\n",
    "    sift_features = np.load('sift_features.npy', allow_pickle=True)\n",
    "    print(f\"Loaded preprocessed images, labels, and SIFT features from disk.\")\n",
    "else:\n",
    "    # 1. Load labels\n",
    "    # This phase involves loading the labels from a MATLAB file. The labels are stored in a .mat file, which is loaded using the scipy.io.loadmat function. The labels are then flattened to ensure they are in a 1D array format. This step is crucial as it provides the ground truth for the classification task.\n",
    "    print(\"Phase 1: Loading labels\")\n",
    "    start_time = time.time()\n",
    "    labels = loadmat('labels.mat')['labels'].flatten()  # Ensure labels are flattened\n",
    "    print(f\"Number of labels: {len(labels)}\")\n",
    "    print(f\"Phase 1 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Adjust labels to be 0-indexed (i.e., from 0 to 5)\n",
    "    # This step adjusts the labels to be 0-indexed by subtracting 1 from each label value. This ensures that the labels are in the range [0, 5], which is required for the classification task. The adjustment is necessary because the original labels might be 1-indexed.\n",
    "    labels = labels - 1\n",
    "\n",
    "    # 2. Load images\n",
    "    # In this phase, the script reads the paths of the images from a text file. Each line in the text file corresponds to the path of an image. These paths are stored in a list for further processing. This step is essential to locate the images that will be used for training and validation.\n",
    "    print(\"Phase 2: Loading image paths\")\n",
    "    start_time = time.time()\n",
    "    with open('cells2.txt', 'r') as f:\n",
    "        image_paths = [line.strip() for line in f.readlines()]\n",
    "    print(f\"Number of image paths: {len(image_paths)}\")\n",
    "    print(f\"Phase 2 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Ensure the number of labels matches the number of image paths\n",
    "    # This assertion ensures that the number of labels matches the number of image paths. It is a crucial validation step to ensure data integrity, as each image must have a corresponding label for the classification task.\n",
    "    assert len(labels) == len(image_paths), \"Number of labels does not match number of image paths\"\n",
    "\n",
    "    # 3. Randomly select 1% of data\n",
    "    # This phase involves randomly selecting 1% of the total dataset for processing. The random.sample function is used to select a subset of indices, which are then used to extract the corresponding image paths and labels. This step helps in reducing the computational load by working with a smaller, representative subset of the data.\n",
    "    print(\"Phase 3: Randomly selecting 1% of data\")\n",
    "    start_time = time.time()\n",
    "    sample_size = int(0.01 * len(image_paths))\n",
    "    sample_indices = random.sample(range(len(image_paths)), sample_size)\n",
    "    sample_paths = [image_paths[i] for i in sample_indices]\n",
    "    sample_labels = labels[sample_indices]\n",
    "    print(f\"Sample size: {sample_size}\")\n",
    "    print(f\"Sample indices size: {len(sample_indices)}\")\n",
    "    print(f\"Sample paths size: {len(sample_paths)}\")\n",
    "    print(f\"Sample labels size: {len(sample_labels)}\")\n",
    "    print(f\"Phase 3 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # 4. Preprocess images\n",
    "    # In this phase, the images are preprocessed to prepare them for input into the CNN. Each image is read in grayscale mode, resized to 128x128 pixels, scaled to a range of [0, 1], and reshaped to add a channel dimension. If an image cannot be loaded, a warning is printed, and the image is skipped. This step ensures that the images are in the correct format for the CNN.\n",
    "    print(\"Phase 4: Preprocessing images\")\n",
    "    start_time = time.time()\n",
    "    sift = cv2.SIFT_create()  # Create SIFT object\n",
    "\n",
    "    def preprocess_image_and_extract_sift(path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Image at path {path} could not be loaded.\")\n",
    "            return None, None\n",
    "        img_resized = cv2.resize(img, (128, 128))  # Resize to 128x128 pixels\n",
    "        keypoints, descriptors = sift.detectAndCompute(img_resized, None)  # Extract SIFT features\n",
    "        img_resized = img_resized / 255.0  # Scaling\n",
    "        img_resized = np.expand_dims(img_resized, axis=-1)  # Add channel dimension\n",
    "        return img_resized, descriptors\n",
    "\n",
    "    images = []\n",
    "    valid_labels = []\n",
    "    sift_features = []\n",
    "    for path, label in zip(sample_paths, sample_labels):\n",
    "        img, descriptors = preprocess_image_and_extract_sift(path)\n",
    "        if img is not None and descriptors is not None:\n",
    "            images.append(img)\n",
    "            valid_labels.append(label)\n",
    "            sift_features.append(descriptors)\n",
    "\n",
    "    # Debug: Print unique label values before saving\n",
    "    # This debug step prints the unique label values before saving the preprocessed images and labels to disk. It helps verify that the labels are correctly adjusted and ensures data integrity before saving.\n",
    "    print(f\"Unique label values before saving: {np.unique(valid_labels)}\")\n",
    "\n",
    "    images = np.array(images)\n",
    "    valid_labels = np.array(valid_labels)\n",
    "    sift_features = np.array(sift_features, dtype=object)  # Save SIFT features\n",
    "    np.save('preprocessed_images.npy', images)\n",
    "    np.save('valid_labels.npy', valid_labels)\n",
    "    np.save('sift_features.npy', sift_features)\n",
    "    print(\"Saved preprocessed images, labels, and SIFT features to disk.\")\n",
    "\n",
    "# Debug: Check the sizes of valid images and labels\n",
    "# This debug step prints the sizes of the valid images and labels arrays. It helps verify that the data has been correctly loaded or preprocessed and provides insight into the amount of data available for training and validation.\n",
    "print(f\"Valid images size: {len(images)}\")\n",
    "print(f\"Valid labels size: {len(valid_labels)}\")\n",
    "\n",
    "# Debug: Print unique label values after loading from disk\n",
    "# This debug step prints the unique label values after loading the preprocessed images and labels from disk. It helps verify that the labels are correctly loaded and ensures data integrity before proceeding to the next steps.\n",
    "print(f\"Unique label values after loading from disk: {np.unique(valid_labels)}\")\n",
    "\n",
    "# Visualize label distribution after loading or preprocessing\n",
    "# This section visualizes the label distribution using a histogram. It provides a graphical representation of the frequency of each label in the dataset, helping to understand the class distribution and identify any potential imbalances.\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(valid_labels, bins=np.arange(7) - 0.5, edgecolor='black')\n",
    "plt.xticks(range(6))\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Label Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Ensure there are valid images before splitting\n",
    "# This assertion ensures that there are valid images loaded or preprocessed before proceeding to the data splitting phase. It is a crucial validation step to prevent errors in subsequent steps if no valid images are available.\n",
    "if len(images) == 0:\n",
    "    raise ValueError(\"No valid images were loaded. Please check the image paths and preprocessing steps.\")\n",
    "\n",
    "print(f\"Phase 4 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# 5. Split data\n",
    "# This phase involves splitting the preprocessed images and their corresponding labels into training and validation sets. The train_test_split function from scikit-learn is used for this purpose, with 20% of the data allocated to the validation set. Stratified splitting is used to ensure that the class distribution is maintained in both sets.\n",
    "print(\"Phase 5: Splitting data into training and validation sets\")\n",
    "start_time = time.time()\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, valid_labels, test_size=0.2, stratify=valid_labels)\n",
    "print(f\"Phase 5 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Debug: Print unique label values after splitting\n",
    "# This debug step prints the unique label values in the training and validation sets after splitting. It helps verify that the labels are correctly split and ensures that the class distribution is maintained in both sets.\n",
    "print(f\"Unique training labels: {np.unique(y_train)}\")\n",
    "print(f\"Unique validation labels: {np.unique(y_val)}\")\n",
    "\n",
    "# Ensure no label value is outside the valid range [0, 5]\n",
    "# This assertion ensures that no label value in the training and validation sets is outside the valid range [0, 5]. It is a crucial validation step to prevent errors during model training and evaluation.\n",
    "assert np.all(y_train >= 0) and np.all(y_train <= 5), \"Training labels contain values outside the range [0, 5]\"\n",
    "assert np.all(y_val >= 0) and np.all(y_val <= 5), \"Validation labels contain values outside the range [0, 5]\"\n",
    "\n",
    "# 6. Build CNN Model\n",
    "# In this phase, a Convolutional Neural Network (CNN) model is built using TensorFlow and Keras. The model consists of convolutional layers, max-pooling layers, a flatten layer, and dense layers. The model is compiled with the Adam optimizer and sparse categorical cross-entropy loss function. This step sets up the architecture of the neural network for training.\n",
    "print(\"Phase 6: Building CNN model\")\n",
    "start_time = time.time()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(128, 128, 1)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')  # 6 classes\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(f\"Phase 6 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# 7. Train model\n",
    "# This phase involves training the CNN model on the training set. The model is trained for a specified number of epochs, and its performance is evaluated on the validation set after each epoch. This step adjusts the model's weights to minimize the loss function and improve accuracy.\n",
    "print(\"Phase 7: Training CNN model\")\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "print(f\"Phase 7 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# 8. Evaluate model\n",
    "# In the final phase, the trained CNN model is evaluated on the validation set to assess its performance. The evaluation metrics, including accuracy, are printed to provide insights into the model's effectiveness. This step helps determine how well the model generalizes to unseen data.\n",
    "print(\"Phase 8: Evaluating model\")\n",
    "start_time = time.time()\n",
    "metrics = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {metrics[1]}\")\n",
    "print(f\"Phase 8 completed in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036a4ad",
   "metadata": {},
   "source": [
    "## Code without much comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0552e9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: Loading labels\n",
      "Number of labels: 63445\n",
      "Phase 1 completed in 0.00 seconds\n",
      "Phase 2: Loading image paths\n",
      "Number of image paths: 63445\n",
      "Phase 2 completed in 0.01 seconds\n",
      "Phase 3: Randomly selecting 1% of data\n",
      "Sample size: 634\n",
      "Sample indices size: 634\n",
      "Sample paths size: 634\n",
      "Sample labels size: 634\n",
      "Phase 3 completed in 0.00 seconds\n",
      "Phase 4: Preprocessing images\n",
      "\n",
      "Example Keypoint and Descriptor:\n",
      "Keypoint: < cv2.KeyPoint 0x30f7b4ab0>\n",
      "Descriptor: [  0.   0.   0.   1.  34.  52.   7.   3.   0.   0.   0.   0.   4.  22.\n",
      "  44.  14.   1.   3.   1.   0.   3.  35.  22.   0.   1.   5.   1.   0.\n",
      "   2.   9.   1.   0.  39.   1.   1.  43.  74.  12.   2.  21. 132.   5.\n",
      "   0.   2.  11.  56. 135. 139.   6.   1.   0.   5. 115. 139.  89.  13.\n",
      "   0.   3.   3.   2.  29.  27.   0.   0.  92.  19.  11.  28.   5.   0.\n",
      "   0.   3. 139.  57.  17.  40.  36.  11.   8.  33.  20.   8.   9. 135.\n",
      " 139.  49.   6.   4.   0.   0.   0.  16.  65.  17.   0.   0.  28.  38.\n",
      "   8.   3.   0.   0.   0.   0.  68. 119. 112.  50.   6.   0.   0.   2.\n",
      "   2.   6.  63. 139.  43.   0.   0.   0.   0.   0.   4.  30.  10.   0.\n",
      "   0.   0.]\n",
      "Warning: Image at path cells/3122.png could not be loaded.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m sift_features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sample_paths, sample_labels):\n\u001b[0;32m---> 70\u001b[0m     img, keypoints, descriptors \u001b[38;5;241m=\u001b[39m preprocess_image_and_extract_sift(path)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m descriptors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m         images\u001b[38;5;241m.\u001b[39mappend(img)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if os.path.exists('preprocessed_images.npy') and os.path.exists('valid_labels.npy') and os.path.exists('sift_features.npy'):\n",
    "    print(\"Loading preprocessed images, labels, and SIFT features from disk.\")\n",
    "    images = np.load('preprocessed_images.npy')\n",
    "    valid_labels = np.load('valid_labels.npy')\n",
    "    sift_features = np.load('sift_features.npy', allow_pickle=True)\n",
    "    print(f\"Loaded preprocessed images, labels, and SIFT features from disk.\")\n",
    "else:\n",
    "    # Phase 1: Load labels\n",
    "    print(\"Phase 1: Loading labels\")\n",
    "    start_time = time.time()\n",
    "    labels = loadmat('labels.mat')['labels'].flatten()  # Ensure labels are flattened\n",
    "    print(f\"Number of labels: {len(labels)}\")\n",
    "    print(f\"Phase 1 completed in {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    labels = labels - 1\n",
    "\n",
    "    # Phase 2: Load images\n",
    "    print(\"Phase 2: Loading image paths\")\n",
    "    start_time = time.time()\n",
    "    with open('cells2.txt', 'r') as f:\n",
    "        image_paths = [line.strip() for line in f.readlines()]\n",
    "    print(f\"Number of image paths: {len(image_paths)}\")\n",
    "    print(f\"Phase 2 completed in {time.time() - start_time:.2f} seconds\")\n",
    "   \n",
    "    assert len(labels) == len(image_paths), \"Number of labels does not match number of image paths\"\n",
    "\n",
    "    # Phase 3: Randomly select 1% of data\n",
    "    print(\"Phase 3: Randomly selecting 1% of data\")\n",
    "    start_time = time.time()\n",
    "    sample_size = int(0.01 * len(image_paths))\n",
    "    sample_indices = random.sample(range(len(image_paths)), sample_size)\n",
    "    sample_paths = [image_paths[i] for i in sample_indices]\n",
    "    sample_labels = labels[sample_indices]\n",
    "    print(f\"Sample size: {sample_size}\")\n",
    "    print(f\"Sample indices size: {len(sample_indices)}\")\n",
    "    print(f\"Sample paths size: {len(sample_paths)}\")\n",
    "    print(f\"Sample labels size: {len(sample_labels)}\")\n",
    "    print(f\"Phase 3 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Phase 4: Preprocessing images\n",
    "    print(\"Phase 4: Preprocessing images\")\n",
    "    start_time = time.time()\n",
    "    sift = cv2.SIFT_create()  # Create SIFT object\n",
    "\n",
    "    def preprocess_image_and_extract_sift(path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Image at path {path} could not be loaded.\")\n",
    "            return None, None\n",
    "        img_resized = cv2.resize(img, (128, 128))  # Resize to 128x128 pixels\n",
    "        keypoints, descriptors = sift.detectAndCompute(img_resized, None)  # Extract SIFT features\n",
    "        img_resized = img_resized / 255.0  # Scaling\n",
    "        img_resized = np.expand_dims(img_resized, axis=-1)  # Add channel dimension\n",
    "        return img_resized, keypoints, descriptors\n",
    "\n",
    "    images = []\n",
    "    valid_labels = []\n",
    "    sift_features = []\n",
    "    for path, label in zip(sample_paths, sample_labels):\n",
    "        img, keypoints, descriptors = preprocess_image_and_extract_sift(path)\n",
    "        if img is not None and descriptors is not None:\n",
    "            images.append(img)\n",
    "            valid_labels.append(label)\n",
    "            sift_features.append((keypoints, descriptors))\n",
    "\n",
    "            # Print one keypoint and its descriptor as an example\n",
    "            if len(sift_features) == 1:  # Only print for the first image\n",
    "                print(\"\\nExample Keypoint and Descriptor:\")\n",
    "                print(\"Keypoint:\", keypoints[0])  # Print the first keypoint\n",
    "                print(\"Descriptor:\", descriptors[0])  # Print the descriptor of the first keypoint\n",
    "\n",
    "    \n",
    "    print(f\"Unique label values before saving: {np.unique(valid_labels)}\")\n",
    "\n",
    "    images = np.array(images)\n",
    "    valid_labels = np.array(valid_labels)\n",
    "    sift_features = np.array(sift_features, dtype=object)  # Save SIFT features\n",
    "    np.save('preprocessed_images.npy', images)\n",
    "    np.save('valid_labels.npy', valid_labels)\n",
    "    np.save('sift_features.npy', sift_features)\n",
    "    print(\"Saved preprocessed images, labels, and SIFT features to disk.\")\n",
    "    print(f\"Phase 4 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "print(f\"Valid images size: {len(images)}\")\n",
    "print(f\"Valid labels size: {len(valid_labels)}\")\n",
    "\n",
    "print(f\"Unique label values after loading from disk: {np.unique(valid_labels)}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(valid_labels, bins=np.arange(7) - 0.5, edgecolor='black')\n",
    "plt.xticks(range(6))\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Label Distribution')\n",
    "plt.show()\n",
    "\n",
    "if len(images) == 0:\n",
    "    raise ValueError(\"No valid images were loaded. Please check the image paths and preprocessing steps.\")\n",
    "\n",
    "# Phase 5: Split data\n",
    "print(\"Phase 5: Splitting data into training and validation sets\")\n",
    "start_time = time.time()\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, valid_labels, test_size=0.2, stratify=valid_labels)\n",
    "print(f\"Phase 5 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "print(f\"Unique training labels: {np.unique(y_train)}\")\n",
    "print(f\"Unique validation labels: {np.unique(y_val)}\")\n",
    "\n",
    "assert np.all(y_train >= 0) and np.all(y_train <= 5), \"Training labels contain values outside the range [0, 5]\"\n",
    "assert np.all(y_val >= 0) and np.all(y_val <= 5), \"Validation labels contain values outside the range [0, 5]\"\n",
    "\n",
    "# Phase 6: Build CNN Model\n",
    "print(\"Phase 6: Building CNN model\")\n",
    "start_time = time.time()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(128, 128, 1)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')  # 6 classes\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(f\"Phase 6 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# 7. Train model\n",
    "print(\"Phase 7: Training CNN model\")\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "print(f\"Phase 7 completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# 8. Evaluate model\n",
    "print(\"Phase 8: Evaluating model\")\n",
    "start_time = time.time()\n",
    "metrics = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {metrics[1]}\")\n",
    "print(f\"Phase 8 completed in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5fa121",
   "metadata": {},
   "source": [
    "## SIFT through the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21dd6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7499dc65",
   "metadata": {},
   "source": [
    "# Phase Based Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c18b233",
   "metadata": {},
   "source": [
    "## Phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46222ade",
   "metadata": {},
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa835015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ed2aac2",
   "metadata": {},
   "source": [
    "## Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4970e",
   "metadata": {},
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930af1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c58fb791",
   "metadata": {},
   "source": [
    "## Phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06c48e",
   "metadata": {},
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fef598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed93f2b6",
   "metadata": {},
   "source": [
    "## Phase 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
