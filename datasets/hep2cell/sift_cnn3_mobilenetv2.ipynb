{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sift cnn descriptors mobilenetv2 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Input, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Function to print timing information\n",
    "def print_timing_info(phase, start_time, end_time):\n",
    "    duration = end_time - start_time\n",
    "    print(f\"{phase} - Start Time: {start_time:.2f}, End Time: {end_time:.2f}, Duration: {duration:.2f} seconds\")\n",
    "\n",
    "# Load File Names and Labels\n",
    "print(\"Loading File Names and Labels\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Load file names from cells2.txt\n",
    "with open('cells2.txt', 'r') as file:\n",
    "    file_names = file.read().splitlines()\n",
    "\n",
    "# Load labels from labels.mat using SciPy\n",
    "labels = scipy.io.loadmat('labels.mat')['labels'].flatten()\n",
    "\n",
    "# Display the number of file names and labels loaded\n",
    "print(f\"Number of file names loaded: {len(file_names)}\")\n",
    "print(f\"Number of labels loaded: {len(labels)}\")\n",
    "\n",
    "# Ensure that the number of file names matches the number of labels\n",
    "assert len(file_names) == len(labels), \"Mismatch between number of file names and labels\"\n",
    "\n",
    "# Filter the file names to ensure they are within the range 1-10,000\n",
    "filtered_file_names = [file for file in file_names if int(os.path.basename(file).split('.')[0]) <= 10000]\n",
    "\n",
    "# Select the first 10,000 images from the filtered dataset\n",
    "selected_file_names = filtered_file_names[:10000]\n",
    "selected_labels = labels[:10000]\n",
    "\n",
    "# Display the number of selected file names and labels\n",
    "print(f\"Number of selected file names: {len(selected_file_names)}\")\n",
    "print(f\"Number of selected labels: {len(selected_labels)}\")\n",
    "\n",
    "# Ensure that the number of selected file names matches the number of selected labels\n",
    "assert len(selected_file_names) == len(selected_labels), \"Mismatch between number of selected file names and labels\"\n",
    "\n",
    "end_time = time.time()\n",
    "print_timing_info(\"Loading Data\", start_time, end_time)\n",
    "\n",
    "# Split Data into Training, Validation, and Testing Sets\n",
    "print(\"\\nSplitting Data into Training, Validation, and Testing Sets\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the selected file names and labels into training, validation, and testing sets\n",
    "train_files, temp_files, train_labels, temp_labels = train_test_split(\n",
    "    selected_file_names, selected_labels, test_size=0.6, random_state=42)\n",
    "\n",
    "val_files, test_files, val_labels, test_labels = train_test_split(\n",
    "    temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the number of files in each set\n",
    "print(f\"Number of training files: {len(train_files)}\")\n",
    "print(f\"Number of validation files: {len(val_files)}\")\n",
    "print(f\"Number of testing files: {len(test_files)}\")\n",
    "\n",
    "# Ensure that the total number of files matches the number of selected files\n",
    "assert len(train_files) + len(val_files) + len(test_files) == len(selected_file_names), \"Mismatch in total number of files after splitting\"\n",
    "\n",
    "end_time = time.time()\n",
    "print_timing_info(\"Splitting Data\", start_time, end_time)\n",
    "\n",
    "# Define the target image size\n",
    "target_size = (96, 96)\n",
    "\n",
    "# Function to preprocess images: resize, convert to grayscale, and normalize\n",
    "def preprocess_image_for_sift(image_path, target_size):\n",
    "    # Read the image from the file\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Check if the image was read correctly\n",
    "    if image is None:\n",
    "        print(f\"Error reading image: {image_path}\")\n",
    "        return None\n",
    "    # Resize the image to the target size\n",
    "    image_resized = cv2.resize(image, target_size)\n",
    "    # Normalize the pixel values to the range [0, 1]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized\n",
    "\n",
    "# Preprocess images with progress reporting\n",
    "def preprocess_images(image_paths, target_size):\n",
    "    images = []\n",
    "    total_images = len(image_paths)\n",
    "    for i, path in enumerate(image_paths):\n",
    "        print(f\"Processing image: {path}\")  # Debug statement to print the image path\n",
    "        image = preprocess_image_for_sift(path, target_size)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "        if (i + 1) % 500 == 0:\n",
    "            percent_done = ((i + 1) / total_images) * 100\n",
    "            print(f\"Processed {i + 1} of {total_images} images ({percent_done:.2f}%)\")\n",
    "    return np.array(images)\n",
    "\n",
    "# Extract SIFT descriptors with progress reporting\n",
    "def extract_sift_descriptors(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    all_descriptors = []\n",
    "    total_images = len(images)\n",
    "    for i, img in enumerate(images):\n",
    "        img_uint8 = (img * 255).astype(np.uint8)\n",
    "        keypoints, descriptors = sift.detectAndCompute(img_uint8, None)\n",
    "        if descriptors is None:\n",
    "            descriptors = np.zeros((1, 128))\n",
    "        all_descriptors.append(descriptors)\n",
    "        if (i + 1) % 500 == 0:\n",
    "            percent_done = ((i + 1) / total_images) * 100\n",
    "            print(f\"Extracted SIFT descriptors for {i + 1} of {total_images} images ({percent_done:.2f}%)\")\n",
    "    return all_descriptors\n",
    "\n",
    "# Check if preprocessed images and descriptors exist\n",
    "preprocessed_data_exists = os.path.exists('train_images.npy') and os.path.exists('val_images.npy') and os.path.exists('test_images.npy') and os.path.exists('train_descriptors.npy') and os.path.exists('val_descriptors.npy') and os.path.exists('test_descriptors.npy')\n",
    "\n",
    "if preprocessed_data_exists:\n",
    "    # Load preprocessed images and descriptors\n",
    "    print(\"\\nLoading Preprocessed Data\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_images = np.load('train_images.npy')\n",
    "    val_images = np.load('val_images.npy')\n",
    "    test_images = np.load('test_images.npy')\n",
    "    train_descriptors = np.load('train_descriptors.npy', allow_pickle=True)\n",
    "    val_descriptors = np.load('val_descriptors.npy', allow_pickle=True)\n",
    "    test_descriptors = np.load('test_descriptors.npy', allow_pickle=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print_timing_info(\"Loading Preprocessed Data\", start_time, end_time)\n",
    "else:\n",
    "    # Preprocess training images\n",
    "    print(\"\\nPreprocessing Images\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_images = preprocess_images(train_files, target_size)\n",
    "    val_images = preprocess_images(val_files, target_size)\n",
    "    test_images = preprocess_images(test_files, target_size)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print_timing_info(\"Preprocessing Images\", start_time, end_time)\n",
    "    \n",
    "    # Save preprocessed images\n",
    "    np.save('train_images.npy', train_images)\n",
    "    np.save('val_images.npy', val_images)\n",
    "    np.save('test_images.npy', test_images)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "train_images = np.array(train_images)\n",
    "val_images = np.array(val_images)\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "# Display the shapes of the preprocessed image arrays\n",
    "print(f\"Shape of training images: {train_images.shape}\")\n",
    "print(f\"Shape of validation images: {val_images.shape}\")\n",
    "print(f\"Shape of testing images: {test_images.shape}\")\n",
    "\n",
    "# Ensure that the number of images matches the number of labels in each set\n",
    "print(f\"Number of training images: {train_images.shape[0]}, Number of training labels: {len(train_labels)}\")\n",
    "print(f\"Number of validation images: {val_images.shape[0]}, Number of validation labels: {len(val_labels)}\")\n",
    "print(f\"Number of testing images: {test_images.shape[0]}, Number of testing labels: {len(test_labels)}\")\n",
    "\n",
    "assert train_images.shape[0] == len(train_labels), \"Mismatch between number of training images and labels\"\n",
    "assert val_images.shape[0] == len(val_labels), \"Mismatch between number of validation images and labels\"\n",
    "assert test_images.shape[0] == len(test_labels), \"Mismatch between number of testing images and labels\"\n",
    "\n",
    "# Visualize 5 images after loading\n",
    "for i in range(5):\n",
    "    plt.imshow(train_images[i], cmap='gray')\n",
    "    plt.title(f\"Training Image {i+1}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Extract SIFT Descriptors\n",
    "if not preprocessed_data_exists:\n",
    "    print(\"\\nExtracting SIFT Descriptors\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_descriptors = extract_sift_descriptors(train_images)\n",
    "    val_descriptors = extract_sift_descriptors(val_images)\n",
    "    test_descriptors = extract_sift_descriptors(test_images)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print_timing_info(\"Extracting SIFT Descriptors\", start_time, end_time)\n",
    "    \n",
    "    # Save extracted descriptors\n",
    "    np.save('train_descriptors.npy', train_descriptors)\n",
    "    np.save('val_descriptors.npy', val_descriptors)\n",
    "    np.save('test_descriptors.npy', test_descriptors)\n",
    "\n",
    "# Filter images and labels to match the descriptors\n",
    "train_images = train_images[:len(train_descriptors)]\n",
    "train_labels = train_labels[:len(train_descriptors)]\n",
    "val_images = val_images[:len(val_descriptors)]\n",
    "val_labels = val_labels[:len(val_descriptors)]\n",
    "test_images = test_images[:len(test_descriptors)]\n",
    "test_labels = test_labels[:len(test_descriptors)]\n",
    "\n",
    "# Calculate percentages of images with descriptors\n",
    "train_percentage = (len(train_descriptors) / len(train_images)) * 100\n",
    "val_percentage = (len(val_descriptors) / len(val_images)) * 100\n",
    "test_percentage = (len(test_descriptors) / len(test_images)) * 100\n",
    "\n",
    "# Calculate average number of descriptors per image\n",
    "train_avg_descriptors = np.mean([len(desc) for desc in train_descriptors])\n",
    "val_avg_descriptors = np.mean([len(desc) for desc in val_descriptors])\n",
    "test_avg_descriptors = np.mean([len(desc) for desc in test_descriptors])\n",
    "\n",
    "# Display the statistics\n",
    "print(f\"Number of descriptors for the first training image: {len(train_descriptors[0]) if train_descriptors[0] is not None else 0}\")\n",
    "print(f\"Number of training images with descriptors: {len(train_descriptors)} ({train_percentage:.2f}%)\")\n",
    "print(f\"Number of validation images with descriptors: {len(val_descriptors)} ({val_percentage:.2f}%)\")\n",
    "print(f\"Number of testing images with descriptors: {len(test_descriptors)} ({test_percentage:.2f}%)\")\n",
    "print(f\"Average number of descriptors per training image: {train_avg_descriptors:.2f}\")\n",
    "print(f\"Average number of descriptors per validation image: {val_avg_descriptors:.2f}\")\n",
    "print(f\"Average number of descriptors per testing image: {test_avg_descriptors:.2f}\")\n",
    "\n",
    "# Ensure that descriptors are extracted for all images\n",
    "assert len(train_descriptors) > 0, \"Failed to extract descriptors for all training images\"\n",
    "assert len(val_descriptors) > 0, \"Failed to extract descriptors for all validation images\"\n",
    "assert len(test_descriptors) > 0, \"Failed to extract descriptors for all testing images\"\n",
    "\n",
    "# Function to pad descriptors to a fixed size\n",
    "def pad_descriptors(descriptors, max_descriptors):\n",
    "    padded_descriptors = np.zeros((max_descriptors, 128))\n",
    "    if descriptors is not None and len(descriptors) > 0:\n",
    "        num_desc = min(len(descriptors), max_descriptors)\n",
    "        padded_descriptors[:num_desc, :] = descriptors[:num_desc, :]\n",
    "    return padded_descriptors\n",
    "\n",
    "# Define the maximum number of descriptors\n",
    "max_descriptors = 4000  # Adjust based on your dataset\n",
    "\n",
    "# Pad descriptors for training, validation, and testing sets\n",
    "train_padded = np.array([pad_descriptors(desc, max_descriptors) if desc is not None else np.zeros((max_descriptors, 128)) for desc in train_descriptors])\n",
    "val_padded = np.array([pad_descriptors(desc, max_descriptors) if desc is not None else np.zeros((max_descriptors, 128)) for desc in val_descriptors])\n",
    "test_padded = np.array([pad_descriptors(desc, max_descriptors) if desc is not None else np.zeros((max_descriptors, 128)) for desc in test_descriptors])\n",
    "\n",
    "# Ensure that the number of padded descriptors matches the number of images\n",
    "assert train_padded.shape[0] == train_images.shape[0], \"Mismatch between number of training images and padded descriptors\"\n",
    "assert val_padded.shape[0] == val_images.shape[0], \"Mismatch between number of validation images and padded descriptors\"\n",
    "assert test_padded.shape[0] == test_images.shape[0], \"Mismatch between number of testing images and padded descriptors\"\n",
    "\n",
    "# Reshape images to match the input shape of the model\n",
    "train_images = train_images.reshape((train_images.shape[0], 96, 96, 1))\n",
    "val_images = val_images.reshape((val_images.shape[0], 96, 96, 1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 96, 96, 1))\n",
    "\n",
    "# Reshape padded descriptors to match the input shape of the model\n",
    "train_padded = train_padded.reshape((train_padded.shape[0], max_descriptors, 128, 1))\n",
    "val_padded = val_padded.reshape((val_padded.shape[0], max_descriptors, 128, 1))\n",
    "test_padded = test_padded.reshape((test_padded.shape[0], max_descriptors, 128, 1))\n",
    "\n",
    "# Define the CNN model for image data\n",
    "image_input = Input(shape=(96, 96, 1), name='image_input')\n",
    "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "image_output = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Define the model for SIFT descriptors\n",
    "desc_input = Input(shape=(max_descriptors, 128, 1), name='desc_input')\n",
    "y = Conv2D(32, (3, 3), activation='relu')(desc_input)\n",
    "y = MaxPooling2D((2, 2))(y)\n",
    "y = Conv2D(64, (3, 3), activation='relu')(y)\n",
    "y = MaxPooling2D((2, 2))(y)\n",
    "y = Flatten()(y)\n",
    "y = Dense(128, activation='relu')(y)\n",
    "desc_output = Dense(128, activation='relu')(y)\n",
    "\n",
    "# Concatenate the outputs of both branches\n",
    "combined = concatenate([image_output, desc_output])\n",
    "\n",
    "# Add final classification layers\n",
    "z = Dense(128, activation='relu')(combined)\n",
    "z = Dropout(0.5)(z)  # Add dropout for regularization\n",
    "z = Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "# Define the final model\n",
    "model = Model(inputs=[image_input, desc_input], outputs=z)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the Model\n",
    "print(\"\\nTraining the Model\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the CNN model using the training data\n",
    "history = model.fit(\n",
    "    [train_images, train_padded], train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=([val_images, val_padded], val_labels)\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print_timing_info(\"Training Model\", start_time, end_time)\n",
    "\n",
    "# Display the training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Visualize SIFT Descriptors\n",
    "\n",
    "# Function to visualize SIFT descriptors on images\n",
    "def visualize_sift(image, keypoints, max_descriptors=5):\n",
    "    overlay = cv2.drawKeypoints(image, keypoints[:max_descriptors], None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    plt.imshow(overlay, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize SIFT descriptors for 3 images\n",
    "for i in range(3):\n",
    "    keypoints, _ = extract_sift_descriptors(train_images[i])\n",
    "    visualize_sift(train_images[i], keypoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
