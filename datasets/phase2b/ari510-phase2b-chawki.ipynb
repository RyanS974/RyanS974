{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b967f6a-3c82-4f14-bdf8-ccb5032a0211",
   "metadata": {},
   "source": [
    "# ARI 510 Phase 2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0562f4a8-c746-4838-8109-7e2a788966be",
   "metadata": {},
   "source": [
    "Project Phase 2b Competition Participation\n",
    "Ryan Smith\n",
    "Project Competing in: chawki's team's.\n",
    "\n",
    "Here is the official description of the task:\n",
    "\n",
    "In this competition, participants will develop models to classify customer reviews into sentiment categories: Positive, Neutral, or Negative. This challenge is ideal for anyone interested in natural language processing and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf1cc3",
   "metadata": {},
   "source": [
    "# The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda143f7",
   "metadata": {},
   "source": [
    "We will use SVM and Random Forest\n",
    "\n",
    "Support Vector Machines (SVMs) are powerful algorithms that excel at creating a clear boundary between different text categories. Imagine drawing a line to separate documents about sports from documents about cooking; SVMs aim to find the best possible line (or hyperplane in higher dimensions) to maximize the separation. They are particularly effective in high-dimensional spaces, which is often the case with text data represented by word frequencies or embeddings. SVMs can also handle non-linear relationships between words and categories by using kernel functions, which essentially transform the data into a space where it's easier to separate. This makes them versatile for various text classification tasks, from sentiment analysis to topic categorization.\n",
    "\n",
    "Random Forest is an ensemble learning method that leverages the wisdom of multiple decision trees to classify text. Imagine having a group of experts, each specializing in different aspects of the text, like vocabulary, grammar, or topic. Each expert (decision tree) makes a prediction based on their knowledge, and the final classification is determined by a majority vote or averaging their predictions. This approach often leads to robust and accurate results because it reduces the risk of overfitting to the training data. Random Forest is particularly useful when dealing with complex datasets and can handle large amounts of text data efficiently. Its ability to capture non-linear relationships and interactions between words makes it a valuable tool for tasks like spam detection, news categorization, and author identification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a0e4a7",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb3a0c0",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941bc5f",
   "metadata": {},
   "source": [
    "## Default Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07bc3002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Datasets loaded.\n",
      "Handling missing values...\n",
      "Missing values handled.\n",
      "Extracting features and labels...\n",
      "Features and labels extracted.\n",
      "Splitting data into training and validation sets...\n",
      "Data split completed.\n",
      "Creating model pipeline...\n",
      "Model pipeline created.\n",
      "Training the model...\n",
      "Model training completed.\n",
      "Validating the model...\n",
      "Validation Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00         4\n",
      "     Neutral       0.50      0.25      0.33         8\n",
      "    Positive       0.71      0.92      0.80        24\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.40      0.39      0.38        36\n",
      "weighted avg       0.58      0.67      0.61        36\n",
      "\n",
      "Testing the model...\n",
      "Model testing completed.\n",
      "Saving predictions to preds.txt...\n",
      "Predictions saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/wht0n7qd6cx0p5f47rhf_qnh0000gn/T/ipykernel_26815/1410263781.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['Review Text'].fillna('', inplace=True)\n",
      "/var/folders/wt/wht0n7qd6cx0p5f47rhf_qnh0000gn/T/ipykernel_26815/1410263781.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['Review Text'].fillna('', inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Default values for hyperparameters\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = pd.read_csv('chawki/data/train_data.csv')\n",
    "test_data = pd.read_csv('chawki/data/test_data.csv')\n",
    "print(\"Datasets loaded.\")\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "train_data['Review Text'].fillna('', inplace=True)\n",
    "train_data.dropna(subset=['Ground_Truth'], inplace=True)\n",
    "test_data['Review Text'].fillna('', inplace=True)\n",
    "print(\"Missing values handled.\")\n",
    "\n",
    "# Features and labels\n",
    "print(\"Extracting features and labels...\")\n",
    "X_train = train_data['Review Text']\n",
    "y_train = train_data['Ground_Truth']\n",
    "X_test = test_data['Review Text']\n",
    "print(\"Features and labels extracted.\")\n",
    "\n",
    "# Split the training data for validation\n",
    "print(\"Splitting data into training and validation sets...\")\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(\"Data split completed.\")\n",
    "\n",
    "# Hyperparameters\n",
    "C = 1.0\n",
    "max_iter = 1000\n",
    "solver = 'lbfgs'\n",
    "\n",
    "# Create a model pipeline\n",
    "print(\"Creating model pipeline...\")\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression(C=C, max_iter=max_iter, solver=solver, multi_class='multinomial'))\n",
    "print(\"Model pipeline created.\")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train_split, y_train_split)\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Validate the model\n",
    "print(\"Validating the model...\")\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Test the model\n",
    "print(\"Testing the model...\")\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Model testing completed.\")\n",
    "\n",
    "# Save predictions to preds.txt\n",
    "print(\"Saving predictions to preds.txt...\")\n",
    "with open('chawki/preds.txt', 'w') as f:\n",
    "    for pred in y_test_pred:\n",
    "        f.write(f\"{pred}\\n\")\n",
    "print(\"Predictions saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1beedc",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346f33a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Datasets loaded.\n",
      "Handling missing values...\n",
      "Missing values handled.\n",
      "Extracting features and labels...\n",
      "Features and labels extracted.\n",
      "Splitting data into training and validation sets...\n",
      "Data split completed.\n",
      "Creating model pipeline...\n",
      "Model pipeline created.\n",
      "Training the model...\n",
      "Model training completed.\n",
      "Validating the model...\n",
      "Validation Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00         4\n",
      "     Neutral       0.00      0.00      0.00         8\n",
      "    Positive       0.67      1.00      0.80        24\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.22      0.33      0.27        36\n",
      "weighted avg       0.44      0.67      0.53        36\n",
      "\n",
      "Testing the model...\n",
      "Model testing completed.\n",
      "Saving predictions to preds.txt...\n",
      "Predictions saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/wht0n7qd6cx0p5f47rhf_qnh0000gn/T/ipykernel_26815/936008838.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['Review Text'].fillna('', inplace=True)\n",
      "/var/folders/wt/wht0n7qd6cx0p5f47rhf_qnh0000gn/T/ipykernel_26815/936008838.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['Review Text'].fillna('', inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Default values for hyperparameters\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = pd.read_csv('chawki/data/train_data.csv')\n",
    "test_data = pd.read_csv('chawki/data/test_data.csv')\n",
    "print(\"Datasets loaded.\")\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "train_data['Review Text'].fillna('', inplace=True)\n",
    "train_data.dropna(subset=['Ground_Truth'], inplace=True)\n",
    "test_data['Review Text'].fillna('', inplace=True)\n",
    "print(\"Missing values handled.\")\n",
    "\n",
    "# Features and labels\n",
    "print(\"Extracting features and labels...\")\n",
    "X_train = train_data['Review Text']\n",
    "y_train = train_data['Ground_Truth']\n",
    "X_test = test_data['Review Text']\n",
    "print(\"Features and labels extracted.\")\n",
    "\n",
    "# Split the training data for validation\n",
    "print(\"Splitting data into training and validation sets...\")\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(\"Data split completed.\")\n",
    "\n",
    "# Hyperparameters\n",
    "C = 0.01\n",
    "max_iter = 3000\n",
    "solver = 'saga'\n",
    "\n",
    "# Create a model pipeline\n",
    "print(\"Creating model pipeline...\")\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression(C=C, max_iter=max_iter, solver=solver, multi_class='multinomial'))\n",
    "print(\"Model pipeline created.\")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train_split, y_train_split)\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Validate the model\n",
    "print(\"Validating the model...\")\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Test the model\n",
    "print(\"Testing the model...\")\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Model testing completed.\")\n",
    "\n",
    "# Save predictions to preds.txt\n",
    "print(\"Saving predictions to preds.txt...\")\n",
    "with open('chawki/preds.txt', 'w') as f:\n",
    "    for pred in y_test_pred:\n",
    "        f.write(f\"{pred}\\n\")\n",
    "print(\"Predictions saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a918236",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fe2bd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Datasets loaded.\n",
      "Handling missing values...\n",
      "Missing values handled.\n",
      "Extracting features and labels...\n",
      "Features and labels extracted.\n",
      "Splitting data into training and validation sets...\n",
      "Data split completed.\n",
      "Creating model pipeline...\n",
      "Model pipeline created.\n",
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/wht0n7qd6cx0p5f47rhf_qnh0000gn/T/ipykernel_26815/871421785.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['Review Text'].fillna('', inplace=True)\n",
      "/var/folders/wt/wht0n7qd6cx0p5f47rhf_qnh0000gn/T/ipykernel_26815/871421785.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['Review Text'].fillna('', inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed.\n",
      "Validating the model...\n",
      "Validation Accuracy: 0.6111111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00         4\n",
      "     Neutral       0.25      0.12      0.17         8\n",
      "    Positive       0.68      0.88      0.76        24\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.31      0.33      0.31        36\n",
      "weighted avg       0.51      0.61      0.55        36\n",
      "\n",
      "Testing the model...\n",
      "Model testing completed.\n",
      "Saving predictions to preds.txt...\n",
      "Predictions saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = pd.read_csv('chawki/data/train_data.csv')\n",
    "test_data = pd.read_csv('chawki/data/test_data.csv')\n",
    "print(\"Datasets loaded.\")\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "train_data['Review Text'].fillna('', inplace=True)\n",
    "train_data.dropna(subset=['Ground_Truth'], inplace=True)\n",
    "test_data['Review Text'].fillna('', inplace=True)\n",
    "print(\"Missing values handled.\")\n",
    "\n",
    "# Features and labels\n",
    "print(\"Extracting features and labels...\")\n",
    "X_train = train_data['Review Text']\n",
    "y_train = train_data['Ground_Truth']\n",
    "X_test = test_data['Review Text']\n",
    "print(\"Features and labels extracted.\")\n",
    "\n",
    "# Split the training data for validation\n",
    "print(\"Splitting data into training and validation sets...\")\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(\"Data split completed.\")\n",
    "\n",
    "# Hyperparameters\n",
    "C = 1.0\n",
    "max_iter = 10000\n",
    "solver = 'saga'\n",
    "penalty = 'l1'\n",
    "\n",
    "# Create a model pipeline\n",
    "print(\"Creating model pipeline...\")\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression(C=C, max_iter=max_iter, solver=solver, multi_class='multinomial', penalty=penalty))\n",
    "print(\"Model pipeline created.\")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train_split, y_train_split)\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Validate the model\n",
    "print(\"Validating the model...\")\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Test the model\n",
    "print(\"Testing the model...\")\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Model testing completed.\")\n",
    "\n",
    "# Save predictions to preds.txt\n",
    "print(\"Saving predictions to preds.txt...\")\n",
    "with open('chawki/preds.txt', 'w') as f:\n",
    "    for pred in y_test_pred:\n",
    "        f.write(f\"{pred}\\n\")\n",
    "print(\"Predictions saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c4a033",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dba964",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd45f532",
   "metadata": {},
   "source": [
    "## Default Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949b230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Datasets loaded.\n",
      "Handling missing values...\n",
      "Missing values handled.\n",
      "Extracting features and labels...\n",
      "Features and labels extracted.\n",
      "Splitting data into training and validation sets...\n",
      "Data split completed.\n",
      "Creating model pipeline...\n",
      "Model pipeline created.\n",
      "Training the model...\n",
      "Model training completed.\n",
      "Validating the model...\n",
      "Validation Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00         4\n",
      "     Neutral       0.00      0.00      0.00         8\n",
      "    Positive       0.67      1.00      0.80        24\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.22      0.33      0.27        36\n",
      "weighted avg       0.44      0.67      0.53        36\n",
      "\n",
      "Testing the model...\n",
      "Model testing completed.\n",
      "Saving predictions to preds.txt...\n",
      "Predictions saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/wht0n7qd6cx0p5f47rhf_qnh0000gn/T/ipykernel_26815/2279083334.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['Review Text'].fillna('', inplace=True)\n",
      "/var/folders/wt/wht0n7qd6cx0p5f47rhf_qnh0000gn/T/ipykernel_26815/2279083334.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['Review Text'].fillna('', inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Default values for hyperparameters\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = pd.read_csv('chawki/data/train_data.csv')\n",
    "test_data = pd.read_csv('chawki/data/test_data.csv')\n",
    "print(\"Datasets loaded.\")\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "train_data['Review Text'].fillna('', inplace=True)\n",
    "train_data.dropna(subset=['Ground_Truth'], inplace=True)\n",
    "test_data['Review Text'].fillna('', inplace=True)\n",
    "print(\"Missing values handled.\")\n",
    "\n",
    "# Features and labels\n",
    "print(\"Extracting features and labels...\")\n",
    "X_train = train_data['Review Text']\n",
    "y_train = train_data['Ground_Truth']\n",
    "X_test = test_data['Review Text']\n",
    "print(\"Features and labels extracted.\")\n",
    "\n",
    "# Split the training data for validation\n",
    "print(\"Splitting data into training and validation sets...\")\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(\"Data split completed.\")\n",
    "\n",
    "# Hyperparameters for RandomForestClassifier\n",
    "n_estimators = 100\n",
    "max_depth = None\n",
    "random_state = None\n",
    "\n",
    "# Create a model pipeline\n",
    "print(\"Creating model pipeline...\")\n",
    "model = make_pipeline(CountVectorizer(), RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state))\n",
    "print(\"Model pipeline created.\")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train_split, y_train_split)\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Validate the model\n",
    "print(\"Validating the model...\")\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Test the model\n",
    "print(\"Testing the model...\")\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Model testing completed.\")\n",
    "\n",
    "# Save predictions to preds.txt\n",
    "print(\"Saving predictions to preds.txt...\")\n",
    "with open('chawki/preds.txt', 'w') as f:\n",
    "    for pred in y_test_pred:\n",
    "        f.write(f\"{pred}\\n\")\n",
    "print(\"Predictions saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2ecbb",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cb61714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Datasets loaded.\n",
      "Handling missing values...\n",
      "Missing values handled.\n",
      "Extracting features and labels...\n",
      "Features and labels extracted.\n",
      "Splitting data into training and validation sets...\n",
      "Data split completed.\n",
      "Creating model pipeline...\n",
      "Model pipeline created.\n",
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/wht0n7qd6cx0p5f47rhf_qnh0000gn/T/ipykernel_26815/2499676677.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['Review Text'].fillna('', inplace=True)\n",
      "/var/folders/wt/wht0n7qd6cx0p5f47rhf_qnh0000gn/T/ipykernel_26815/2499676677.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['Review Text'].fillna('', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed.\n",
      "Validating the model...\n",
      "Validation Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00         4\n",
      "     Neutral       0.00      0.00      0.00         8\n",
      "    Positive       0.67      1.00      0.80        24\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.22      0.33      0.27        36\n",
      "weighted avg       0.44      0.67      0.53        36\n",
      "\n",
      "Testing the model...\n",
      "Model testing completed.\n",
      "Saving predictions to preds.txt...\n",
      "Predictions saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Modified values for hyperparameters\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = pd.read_csv('chawki/data/train_data.csv')\n",
    "test_data = pd.read_csv('chawki/data/test_data.csv')\n",
    "print(\"Datasets loaded.\")\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "train_data['Review Text'].fillna('', inplace=True)\n",
    "train_data.dropna(subset=['Ground_Truth'], inplace=True)\n",
    "test_data['Review Text'].fillna('', inplace=True)\n",
    "print(\"Missing values handled.\")\n",
    "\n",
    "# Features and labels\n",
    "print(\"Extracting features and labels...\")\n",
    "X_train = train_data['Review Text']\n",
    "y_train = train_data['Ground_Truth']\n",
    "X_test = test_data['Review Text']\n",
    "print(\"Features and labels extracted.\")\n",
    "\n",
    "# Split the training data for validation\n",
    "print(\"Splitting data into training and validation sets...\")\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(\"Data split completed.\")\n",
    "\n",
    "# Hyperparameters for RandomForestClassifier\n",
    "n_estimators = 20000\n",
    "max_depth = 5\n",
    "random_state = 42\n",
    "min_samples_split = 100\n",
    "min_samples_leaf = 50\n",
    "\n",
    "# Create a model pipeline\n",
    "print(\"Creating model pipeline...\")\n",
    "model = make_pipeline(CountVectorizer(), RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state))\n",
    "print(\"Model pipeline created.\")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train_split, y_train_split)\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Validate the model\n",
    "print(\"Validating the model...\")\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Test the model\n",
    "print(\"Testing the model...\")\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Model testing completed.\")\n",
    "\n",
    "# Save predictions to preds.txt\n",
    "print(\"Saving predictions to preds.txt...\")\n",
    "with open('chawki/preds.txt', 'w') as f:\n",
    "    for pred in y_test_pred:\n",
    "        f.write(f\"{pred}\\n\")\n",
    "print(\"Predictions saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
